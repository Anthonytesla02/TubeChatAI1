import os
import requests
import json
import logging
from typing import Dict, List
from rag_service import search_similar_chunks

# Mistral AI API configuration
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "j4h3leTe769ILXBLzwsMkrKEzWqZjOTj")
MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"

def generate_chat_response(user_query: str, relevant_chunks: List[Dict]) -> Dict:
    """
    Generate a chat response using Mistral AI with RAG context
    """
    try:
        # Prepare context from relevant chunks
        context = ""
        if relevant_chunks:
            context_parts = []
            for i, chunk in enumerate(relevant_chunks[:3]):  # Use top 3 chunks
                context_parts.append(f"Context {i+1}: {chunk['chunk_text']}")
            context = "\n\n".join(context_parts)
        
        # Create the prompt
        system_prompt = """You are a helpful AI assistant that answers questions based on YouTube video transcripts. 
        
Your task is to:
1. Answer questions using ONLY the provided transcript context
2. Be conversational and helpful
3. If the context doesn't contain relevant information, politely say you don't have that information in the transcript
4. Cite specific parts of the transcript when relevant
5. Keep responses concise but informative

Always base your answers on the provided context. Do not make up information that isn't in the transcript."""

        user_prompt = f"""Context from the video transcript:
{context}

User Question: {user_query}

Please answer the question based on the transcript context provided above."""

        # Prepare the API request
        headers = {
            "Authorization": f"Bearer {MISTRAL_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "mistral-tiny",  # Using the smallest/fastest model
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "max_tokens": 500,
            "temperature": 0.7,
            "top_p": 1.0,
            "stream": False
        }
        
        # Make the API request
        response = requests.post(
            MISTRAL_API_URL,
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                ai_response = result["choices"][0]["message"]["content"]
                
                # Calculate confidence score based on similarity scores
                confidence_score = 0.0
                if relevant_chunks:
                    avg_similarity = sum(chunk.get('similarity', 0) for chunk in relevant_chunks) / len(relevant_chunks)
                    confidence_score = min(avg_similarity * 100, 95)  # Cap at 95%
                
                # Prepare context chunks for frontend
                context_chunks = []
                for chunk in relevant_chunks[:3]:
                    context_chunks.append({
                        'text': chunk['chunk_text'][:200] + "..." if len(chunk['chunk_text']) > 200 else chunk['chunk_text'],
                        'similarity': round(chunk.get('similarity', 0) * 100, 1)
                    })
                
                return {
                    'response': ai_response,
                    'context_chunks': context_chunks,
                    'confidence_score': round(confidence_score, 1)
                }
            else:
                raise Exception("No response generated by Mistral AI")
        
        elif response.status_code == 401:
            raise Exception("Invalid Mistral AI API key")
        elif response.status_code == 429:
            raise Exception("Mistral AI API rate limit exceeded. Please try again later.")
        else:
            error_msg = f"Mistral AI API error: {response.status_code}"
            try:
                error_detail = response.json()
                if 'error' in error_detail:
                    error_msg += f" - {error_detail['error'].get('message', '')}"
            except:
                pass
            raise Exception(error_msg)
            
    except requests.exceptions.Timeout:
        raise Exception("Request to Mistral AI timed out. Please try again.")
    except requests.exceptions.ConnectionError:
        raise Exception("Failed to connect to Mistral AI. Please check your internet connection.")
    except Exception as e:
        logging.error(f"Error generating Mistral AI response: {e}")
        if "Mistral AI" in str(e):
            raise e
        else:
            raise Exception(f"Failed to generate response: {str(e)}")

def test_mistral_connection():
    """Test if Mistral AI API is accessible"""
    try:
        headers = {
            "Authorization": f"Bearer {MISTRAL_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "mistral-tiny",
            "messages": [{"role": "user", "content": "Hello"}],
            "max_tokens": 10
        }
        
        response = requests.post(
            MISTRAL_API_URL,
            headers=headers,
            json=data,
            timeout=10
        )
        
        return response.status_code == 200
        
    except Exception as e:
        logging.error(f"Mistral AI connection test failed: {e}")
        return False
